{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dichasus_cf0x import training_set\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of datapoints in training set (for progress bar)\n",
    "TOTAL_DATAPOINTS = sum(1 for _ in training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBCARRIERS = tf.shape(training_set.take(1).get_single_element()[0])[-1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rissanen MDL, as described in\n",
    "# Xinrong Li and Kaveh Pahlavan: \"Super-resolution TOA estimation with diversity for indoor geolocation\" in IEEE Transactions on Wireless Communications\n",
    "def rissanen_mdl(eigenvalues, chunkcount, use_fbcm = False, L = 100):\n",
    "    eigenvalues = np.sort(np.real(eigenvalues))[::-1]\n",
    "    \n",
    "    M = chunkcount\n",
    "    mdl = np.zeros(L)\n",
    "\n",
    "    for k in range(L):\n",
    "        mdl[k] = -M * (L - k) * (np.sum(np.log(eigenvalues[k:L]) / (L - k)) - np.log(np.sum(eigenvalues[k:L]) / (L - k)))\n",
    "        if use_fbcm:\n",
    "            mdl[k] = mdl[k] + (1/4) * k * (2 * L - k + 1) * np.log(M)\n",
    "        else:\n",
    "            mdl[k] = mdl[k] + (1/2) * k * (2 * L - k) * np.log(M)\n",
    "\n",
    "    return np.argmin(mdl)\n",
    "\n",
    "# root-MUSIC algorithm implementation\n",
    "# returns delays and powers, sorted by power from strongest to weakest\n",
    "def rootmusic_toa(eigval, eigvec, source_count):\n",
    "    Qn = np.asmatrix(eigvec[:,source_count:])\n",
    "    C = np.matmul(Qn, Qn.H)\n",
    "\n",
    "    coeffs = np.zeros((len(eigval) - 1,), dtype = np.complex128)\n",
    "    for i in range(1, len(eigval)):\n",
    "        coeffs[i - 1] += np.sum(np.diag(C, i))\n",
    "\n",
    "    coeffs = np.hstack((coeffs[::-1], np.sum(np.diag(C)), coeffs.conj()))\n",
    "    roots = np.roots(coeffs)\n",
    "    roots = roots[abs(roots) < 1]\n",
    "    powers = 1 / (1 - np.abs(roots))\n",
    "    largest_roots = np.argsort(powers)[::-1]\n",
    "\n",
    "    source_delays = -SUBCARRIERS * np.angle(roots[largest_roots[:source_count]]) / (2 * np.pi)\n",
    "    source_powers = powers[largest_roots[:source_count]]\n",
    "\n",
    "    return source_delays, source_powers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expects csi in shape (arrays, antenna_rows, antenna_columns, subcarriers)\n",
    "def estimate_toas(csi, chunksize = None):\n",
    "    chunksize = np.shape(csi)[-1] if chunksize is None else chunksize\n",
    "    chunkcount = np.shape(csi)[-1] // chunksize\n",
    "\n",
    "    # Compute array covariance matrix R and perform eigenvector / eigenvalue decomposition\n",
    "    csi_chunked = np.reshape(csi, (np.shape(csi)[0], np.shape(csi)[1], np.shape(csi)[2], chunkcount, chunksize))\n",
    "    R = np.einsum(\"armcs,armct->ast\", csi_chunked, np.conj(csi_chunked))\n",
    "\n",
    "    # Use forwardâ€“backward correlation matrix\n",
    "    R = (R + np.flip(np.conj(R), axis = (1, 2))) / 2\n",
    "    eigval, eigvec = np.linalg.eigh(R)\n",
    "    eigval = eigval[:,::-1]\n",
    "    eigvec = eigvec[:,:,::-1]\n",
    "\n",
    "    toa_by_array = np.zeros(np.shape(csi)[0])\n",
    "    for array in range(np.shape(csi)[0]):\n",
    "        source_count = rissanen_mdl(eigval[array,:], chunkcount, use_fbcm = True)\n",
    "        delays, powers = rootmusic_toa(eigval[array], eigvec[array], source_count)\n",
    "    \n",
    "        # Out of the strongest \"source_count // 2\" paths (or at least 1, but maximum 5), pick the earliest one\n",
    "        if len(delays) > 0:\n",
    "            toa_by_array[array] = np.min(delays[:min(5, max(source_count // 2, 1))])\n",
    "\n",
    "    return toa_by_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_toas = []\n",
    "\n",
    "for csi, pos, time in tqdm.tqdm(training_set.take(10), total = TOTAL_DATAPOINTS):\n",
    "    estimated_toas.append(estimate_toas(csi, chunksize = 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_toas = np.asarray(estimated_toas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"results/estimated_toas.npy\", estimated_toas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
