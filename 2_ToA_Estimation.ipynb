{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 08:46:50.024027: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 08:46:50.809921: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-10-20 08:46:51.717674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 08:46:51.741494: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 08:46:51.741799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 08:46:51.743556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 08:46:51.743789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 08:46:51.743998: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 08:46:52.243163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 08:46:52.243433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 08:46:52.243644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 08:46:52.243820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14118 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:81:00.0, compute capability: 8.9\n",
      "2023-10-20 08:46:52.847606: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2023-10-20 08:46:52.878010: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    }
   ],
   "source": [
    "from dichasus_cf0x import training_set\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of datapoints in training set (for progress bar)\n",
    "TOTAL_DATAPOINTS = sum(1 for _ in training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBCARRIERS = tf.shape(training_set.take(1).get_single_element()[0])[-1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rissanen MDL, as described in\n",
    "# Xinrong Li and Kaveh Pahlavan: \"Super-resolution TOA estimation with diversity for indoor geolocation\" in IEEE Transactions on Wireless Communications\n",
    "def rissanen_mdl(eigenvalues, chunkcount, use_fbcm = False, L = 100):\n",
    "    eigenvalues = np.sort(np.real(eigenvalues))[::-1]\n",
    "    \n",
    "    M = chunkcount\n",
    "    mdl = np.zeros(L)\n",
    "\n",
    "    for k in range(L):\n",
    "        mdl[k] = -M * (L - k) * (np.sum(np.log(eigenvalues[k:L]) / (L - k)) - np.log(np.sum(eigenvalues[k:L]) / (L - k)))\n",
    "        if use_fbcm:\n",
    "            mdl[k] = mdl[k] + (1/4) * k * (2 * L - k + 1) * np.log(M)\n",
    "        else:\n",
    "            mdl[k] = mdl[k] + (1/2) * k * (2 * L - k) * np.log(M)\n",
    "\n",
    "    return np.argmin(mdl)\n",
    "\n",
    "# root-MUSIC algorithm implementation\n",
    "# returns delays and powers, sorted by power from strongest to weakest\n",
    "def rootmusic_toa(eigval, eigvec, source_count):\n",
    "    Qn = np.asmatrix(eigvec[:,source_count:])\n",
    "    C = np.matmul(Qn, Qn.H)\n",
    "    \n",
    "    coeffs = np.asarray([np.trace(C, offset = diag) for diag in range(1, len(C))])\n",
    "\n",
    "    # Remove some of the smaller noise coefficients, trade accuracy for speed\n",
    "    coeffs = np.hstack((coeffs[::-1], np.trace(C), coeffs.conj()))\n",
    "\n",
    "    roots = np.roots(coeffs)\n",
    "    roots = roots[abs(roots) < 1]\n",
    "    powers = 1 / (1 - np.abs(roots))\n",
    "    largest_roots = np.argsort(powers)[::-1]\n",
    "\n",
    "    source_delays = -SUBCARRIERS * np.angle(roots[largest_roots[:source_count]]) / (2 * np.pi)\n",
    "    source_powers = powers[largest_roots[:source_count]]\n",
    "\n",
    "    return source_delays, source_powers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expects csi in shape (arrays, antenna_rows, antenna_columns, subcarriers)\n",
    "def estimate_toas(csi, chunksize = None):\n",
    "    chunksize = np.shape(csi)[-1] if chunksize is None else chunksize\n",
    "    chunkcount = np.shape(csi)[-1] // chunksize\n",
    "\n",
    "    # Compute array covariance matrix R and perform eigenvector / eigenvalue decomposition\n",
    "    csi_chunked = np.reshape(csi, (np.shape(csi)[0], np.shape(csi)[1], np.shape(csi)[2], chunkcount, chunksize))\n",
    "    R = np.einsum(\"armcs,armct->ast\", csi_chunked, np.conj(csi_chunked))\n",
    "\n",
    "    # Use forward–backward correlation matrix\n",
    "    R = (R + np.flip(np.conj(R), axis = (1, 2))) / 2\n",
    "    eigval, eigvec = np.linalg.eigh(R)\n",
    "    eigval = eigval[:,::-1]\n",
    "    eigvec = eigvec[:,:,::-1]\n",
    "\n",
    "    toa_by_array = np.zeros(np.shape(csi)[0])\n",
    "    for array in range(np.shape(csi)[0]):\n",
    "        source_count = rissanen_mdl(eigval[array,:], chunkcount, use_fbcm = True, L = chunksize // 2)\n",
    "        delays, powers = rootmusic_toa(eigval[array], eigvec[array], source_count)\n",
    "    \n",
    "        # Out of the strongest \"source_count // 2\" paths (or at least 1, but maximum 5), pick the earliest one\n",
    "        if len(delays) > 0:\n",
    "            toa_by_array[array] = np.min(delays[:min(5, max(source_count // 2, 1))])\n",
    "\n",
    "    return toa_by_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 624/20997 [00:10<05:50, 58.10it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m estimated_toas \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mestimate_toas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcsi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTOTAL_DATAPOINTS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m estimated_toas \u001b[38;5;241m=\u001b[39m [\u001b[43mestimate_toas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m csi, pos, time \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(training_set, total \u001b[38;5;241m=\u001b[39m TOTAL_DATAPOINTS)]\n",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m, in \u001b[0;36mestimate_toas\u001b[0;34m(csi, chunksize)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Compute array covariance matrix R and perform eigenvector / eigenvalue decomposition\u001b[39;00m\n\u001b[1;32m      7\u001b[0m csi_chunked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(csi, (np\u001b[38;5;241m.\u001b[39mshape(csi)[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mshape(csi)[\u001b[38;5;241m1\u001b[39m], np\u001b[38;5;241m.\u001b[39mshape(csi)[\u001b[38;5;241m2\u001b[39m], chunkcount, chunksize))\n\u001b[0;32m----> 8\u001b[0m R \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marmcs,armct->ast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsi_chunked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsi_chunked\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Use forward–backward correlation matrix\u001b[39;00m\n\u001b[1;32m     11\u001b[0m R \u001b[38;5;241m=\u001b[39m (R \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mflip(np\u001b[38;5;241m.\u001b[39mconj(R), axis \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numpy/core/einsumfunc.py:1371\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m specified_out:\n\u001b[1;32m   1370\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out\n\u001b[0;32m-> 1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mc_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;66;03m# repeat default values here\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m valid_einsum_kwargs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcasting\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimated_toas = [estimate_toas(csi, chunksize = 256) for csi, pos, time in tqdm.tqdm(training_set, total = TOTAL_DATAPOINTS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_toas = np.asarray(estimated_toas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"results/estimated_toas.npy\", estimated_toas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
